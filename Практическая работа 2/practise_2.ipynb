{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_first_data(data):\n",
    "    with open('Answers/first_task.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "    print(\"Results have been written to results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_task():\n",
    "\n",
    "    matrix =  np.load('./55/first_task.npy')\n",
    "\n",
    "    total_sum = float(np.sum(matrix))\n",
    "    arithmetic_mean = float(np.mean(matrix))\n",
    "\n",
    "    main_diagonal = np.diagonal(matrix)\n",
    "    main_diagonal_sum = float(np.sum(main_diagonal))\n",
    "    main_diagonal_mean = float(np.mean(main_diagonal))\n",
    "\n",
    "    secondary_diagonal = np.diagonal(np.fliplr(matrix))\n",
    "    secondary_diagonal_sum = float(np.sum(secondary_diagonal))\n",
    "    secondary_diagonal_mean = float(np.mean(secondary_diagonal))\n",
    "\n",
    "    max_value = float(np.max(matrix))\n",
    "    min_value = float(np.min(matrix))\n",
    "\n",
    "    results = {\n",
    "        \"sum\": total_sum,\n",
    "        \"avr\": arithmetic_mean,\n",
    "        \"sumMD\": main_diagonal_sum,\n",
    "        \"avrMD\": main_diagonal_mean,\n",
    "        \"sumSD\": secondary_diagonal_sum,\n",
    "        \"avrSD\": secondary_diagonal_mean,\n",
    "        \"max_value\": max_value,\n",
    "        \"min_value\": min_value\n",
    "    }\n",
    "    \n",
    "    save_first_data(results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to results.json\n"
     ]
    }
   ],
   "source": [
    "first_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_task():\n",
    "    matrix = np.load('./55/second_task.npy')\n",
    "\n",
    "    threshold = 555 #(500 + 55 вариант)\n",
    "\n",
    "    indices = np.argwhere(matrix > threshold)\n",
    "\n",
    "    x = indices[:, 0]\n",
    "    y = indices[:, 1]\n",
    "    z = matrix[indices[:, 0], indices[:, 1]]\n",
    "\n",
    "    np.savez('Answers/second_task.npz', x=x, y=y, z=z)\n",
    "    np.savez_compressed('Answers/second_task_compressed.npz', x=x, y=y, z=z)\n",
    "\n",
    "    size_normal = os.path.getsize('Answers/second_task.npz')\n",
    "    size_compressed = os.path.getsize('Answers/second_task_compressed.npz')\n",
    "\n",
    "    print(f\"Размер results.npz: {size_normal} bytes\")\n",
    "    print(f\"Размер results_compressed.npz: {size_compressed} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер results.npz: 4104 bytes\n",
      "Размер results_compressed.npz: 1198 bytes\n"
     ]
    }
   ],
   "source": [
    "second_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import msgpack\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_task():\n",
    "\n",
    "    with open('./55/third_task.json', 'r',encoding='utf-8') as json_file:\n",
    "        products = json.load(json_file)\n",
    "\n",
    "    aggregated_info = list()\n",
    "\n",
    "    for product in products:\n",
    "        prices = product.get('prices', [])\n",
    "        \n",
    "        if prices:\n",
    "            average_price = sum(prices) / len(prices)\n",
    "            max_price = max(prices)\n",
    "            min_price = min(prices)\n",
    "        else:\n",
    "            average_price = None  \n",
    "            min_price = None\n",
    "            max_price = None\n",
    "\n",
    "        aggregated_info.append({\n",
    "            'average_price': average_price,\n",
    "            'max_price': max_price,\n",
    "            'min_price': min_price\n",
    "        })\n",
    "\n",
    "    with open('Answers/third_task_aggregated_info.json', 'w') as json_out:\n",
    "        json.dump(aggregated_info, json_out, indent=4)\n",
    "\n",
    "    with open('Answers/third_task_aggregated_info.msgpack', 'wb') as msgpack_out:\n",
    "        msgpack.pack(aggregated_info, msgpack_out)\n",
    "\n",
    "    size_json = os.path.getsize('Answers/third_task_aggregated_info.json')\n",
    "    size_msgpack = os.path.getsize('Answers/third_task_aggregated_info.msgpack')\n",
    "\n",
    "    print(f\"Размер third_task_aggregated_info.json: {size_json} bytes\")\n",
    "    print(f\"Размер third_task_aggregated_info.msgpack: {size_msgpack} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер third_task_aggregated_info.json: 104349 bytes\n",
      "Размер third_task_aggregated_info.msgpack: 38877 bytes\n"
     ]
    }
   ],
   "source": [
    "third_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourth_task():\n",
    "\n",
    "    with open('55/fourth_task_products.json', 'rb') as pkl_file:\n",
    "        products = pickle.load(pkl_file)\n",
    "\n",
    "    with open('55/fourth_task_updates.json', 'r',encoding='utf-8') as json_file:\n",
    "        price_updates = json.load(json_file)\n",
    "\n",
    "    for update in price_updates:\n",
    "        product_name = update['name']\n",
    "        method = update['method']\n",
    "        param = update['param']\n",
    "\n",
    "        for product in products:\n",
    "            if product['name'] == product_name:\n",
    "                if method == \"add\":\n",
    "                    product['price'] += param\n",
    "                elif method == \"sub\":\n",
    "                    product['price'] -= param\n",
    "                elif method == \"percent+\":\n",
    "                    product['price'] *= (1 + param)\n",
    "                elif method == \"percent-\":\n",
    "                    product['price'] *= (1 - param)\n",
    "\n",
    "\n",
    "    with open('Answers/fourth_task_modified_products.pkl', 'wb') as modified_pkl_file:\n",
    "        pickle.dump(products, modified_pkl_file)\n",
    "\n",
    "    print(\"Данные сохранены в fourth_task_modified_products.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные сохранены в fourth_task_modified_products.pkl\n"
     ]
    }
   ],
   "source": [
    "fourth_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для данного задания был взять датасет с ([Kaggle](https://www.kaggle.com/datasets/mariusborel/electric-vhicule-population-data?resource=download)) весом 50 МБ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sizes():\n",
    "    file_sizes = {\n",
    "    'CSV Size': os.path.getsize('Answers/fifth_task_dataset.csv'),\n",
    "    'JSON Size': os.path.getsize('Answers/fifth_task_dataset.json'),\n",
    "    'MsgPack Size': os.path.getsize('Answers/fifth_task_dataset.msgpack'),\n",
    "    'PKL Size': os.path.getsize('Answers/fifth_task_dataset.pkl')\n",
    "    }\n",
    "\n",
    "    print(\"File Sizes (in bytes):\")\n",
    "    for format, size in file_sizes.items():\n",
    "        print(f\"{format}: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_stats(df):\n",
    "\n",
    "    selected_fields = ['VIN (1-10)',\n",
    "                       'County','City',\n",
    "                       'State',\n",
    "                       'Postal Code',\n",
    "                       'Model Year',\n",
    "                       'Make',\n",
    "                       'Model',\n",
    "                       'Electric Vehicle Type',\n",
    "                       'Clean Alternative Fuel Vehicle (CAFV) Eligibility',\n",
    "                       'Electric Range']\n",
    "    numerical_fields = ['Postal Code', 'Model Year', 'Electric Range'] \n",
    "    categorical_fields = ['VIN (1-10)',\n",
    "                          'County',\n",
    "                          'City',\n",
    "                          'State',\n",
    "                          'Make',\n",
    "                          'Model',\n",
    "                          'Electric Vehicle Type',\n",
    "                          'Clean Alternative Fuel Vehicle (CAFV) Eligibility']\n",
    "\n",
    "    df_selected = df[selected_fields]\n",
    "\n",
    "    statistics = {}\n",
    "\n",
    "    for field in numerical_fields:\n",
    "        statistics[field] = {\n",
    "            'max': float(df_selected[field].max()),\n",
    "            'min': float(df_selected[field].min()),\n",
    "            'mean': float(df_selected[field].mean()),\n",
    "            'sum': float(df_selected[field].sum()),\n",
    "            'std_dev': float(df_selected[field].std())\n",
    "        }\n",
    "\n",
    "    for field in categorical_fields:\n",
    "        statistics[field] = df_selected[field].value_counts().to_dict()\n",
    "\n",
    "    return df_selected, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fifth_task():\n",
    "    file_path = '55/Electric_Vehicle_Population_Data.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df_selected, statistics = count_stats(df)\n",
    "\n",
    "    with open('Answers/fifth_task_statistics.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(statistics, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    df_selected.to_csv('Answers/fifth_task_dataset.csv', index=False)\n",
    "    df_selected.to_json('Answers/fifth_task_dataset.json', orient='records', lines=True)\n",
    "    df_selected.to_pickle('Answers/fifth_task_dataset.pkl')\n",
    "\n",
    "    df_dict = df_selected.to_dict()\n",
    "    with open('Answers/fifth_task_dataset.msgpack', 'wb') as msgpack_out:\n",
    "        msgpack.pack(df_dict, msgpack_out)\n",
    "\n",
    "    file_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Sizes (in bytes):\n",
      "CSV Size: 30096055\n",
      "JSON Size: 68923937\n",
      "MsgPack Size: 40686638\n",
      "PKL Size: 13545287\n"
     ]
    }
   ],
   "source": [
    "fifth_task()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
