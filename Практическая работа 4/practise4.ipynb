{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_df(filepath):\n",
    "    try:\n",
    "        df = pd.read_pickle(filepath)\n",
    "        df = pd.DataFrame(df)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_sql(df):\n",
    "    try:\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        df.to_sql('task1', conn, if_exists='replace', index=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data,filename):\n",
    "    with open(f'./Answers/{filename}.json', 'w',encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_rows(tableName):\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"SELECT * FROM {tableName} ORDER BY city LIMIT 10;\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    conn.close()\n",
    "    return rows, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_statistic(tableName):\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"SELECT \n",
    "                SUM(year) AS total_sum,\n",
    "                MIN(year) AS min_value,\n",
    "                MAX(year) AS max_value,\n",
    "                AVG(year) AS average_value\n",
    "            FROM {tableName};\"\"\"\n",
    "    cursor.execute(query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    total_sum, min_value, max_value, average_value = result\n",
    "    return total_sum, min_value, max_value, average_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency(tableName):\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"SELECT \n",
    "                city, \n",
    "                COUNT(*) AS frequency\n",
    "            FROM {tableName}\n",
    "            GROUP BY city;\n",
    "            \"\"\"\n",
    "    cursor.execute(query)\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtred_data(tableName):\n",
    "    filter_predicate = 'year > 1750'\n",
    "    numeric_field = 'year'\n",
    "    num_rows = 10\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = f\"\"\"SELECT * \n",
    "                FROM {tableName} \n",
    "                WHERE {filter_predicate} \n",
    "                ORDER BY {numeric_field} \n",
    "                LIMIT {num_rows};\"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall() \n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    cursor.close()\n",
    "    return results, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_task():\n",
    "\n",
    "    filepath = './55/1-2/item.pkl'\n",
    "    df = pickle_to_df(filepath)\n",
    "    push_to_sql(df)\n",
    "\n",
    "    rows, column_names = get_first_rows('task1')\n",
    "    results = [dict(zip(column_names, row)) for row in rows]\n",
    "    save_json(results,'first_name_1')\n",
    "\n",
    "    total_sum, min_value, max_value, average_value = count_statistic('task1')\n",
    "    print(f\"Сумма: {total_sum}\")\n",
    "    print(f\"Минимум: {min_value}\")\n",
    "    print(f\"Максимум: {max_value}\")\n",
    "    print(f\"Среднее: {average_value}\")\n",
    "\n",
    "    result = count_frequency('task1')\n",
    "    print('Часота встречаемости для поля city')\n",
    "    print(result)\n",
    "\n",
    "    data, column_names = get_filtred_data('task1')\n",
    "    results = [dict(zip(column_names, row)) for row in data]\n",
    "    save_json(results,'first_task_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма: 167544\n",
      "Минимум: 1602\n",
      "Максимум: 2021\n",
      "Среднее: 1801.5483870967741\n",
      "Часота встречаемости для поля city\n",
      "('Авилес', 1)\n",
      "[(962206, 'Кладбище 81', 'Минская улица 22', 'Ереван', 230802, 8, 1751, 1, 70651040, 27464), (998057, 'Мост 45', 'Парковая улица 73', 'Алма-Ата', 468101, 10, 1752, 0, 416200296, 5707), (874441, 'Мостки 69', 'Лесная улица 40', 'Луарка', 980504, 10, 1753, 0, 519592192, 96225), (995080, 'Кошара 30', 'Московская улица 66', 'Луго', 344867, 4, 1755, 0, 474111671, 92600), (549814, 'Банк 91', 'Солнечная улица 74', 'Санкт-Петербург', 222190, 10, 1766, 0, 103855338, 73410), (805933, 'Фабрика 34', 'Морская улица 88', 'Камбадос', 401601, 9, 1768, 0, 209829012, 40960), (172959, 'Ламарий 64', 'Московская улица 22', 'Монсон', 855170, 8, 1769, 0, 356079378, 31421), (845579, 'Йодль 89', 'Садовая улица 10', 'Осера', 845968, 5, 1773, 0, 861712029, 43471), (849968, 'Логово 41', 'Минская улица 40', 'Осера', 573342, 1, 1774, 1, 824486436, 55931), (246664, 'Скворечник 54', 'Зимняя улица 64', 'Виго', 461581, 9, 1778, 1, 396707817, 71371)] ['id', 'name', 'street', 'city', 'zipcode', 'floors', 'year', 'parking', 'prob_price', 'views']\n",
      "[{'id': 962206, 'name': 'Кладбище 81', 'street': 'Минская улица 22', 'city': 'Ереван', 'zipcode': 230802, 'floors': 8, 'year': 1751, 'parking': 1, 'prob_price': 70651040, 'views': 27464}, {'id': 998057, 'name': 'Мост 45', 'street': 'Парковая улица 73', 'city': 'Алма-Ата', 'zipcode': 468101, 'floors': 10, 'year': 1752, 'parking': 0, 'prob_price': 416200296, 'views': 5707}, {'id': 874441, 'name': 'Мостки 69', 'street': 'Лесная улица 40', 'city': 'Луарка', 'zipcode': 980504, 'floors': 10, 'year': 1753, 'parking': 0, 'prob_price': 519592192, 'views': 96225}, {'id': 995080, 'name': 'Кошара 30', 'street': 'Московская улица 66', 'city': 'Луго', 'zipcode': 344867, 'floors': 4, 'year': 1755, 'parking': 0, 'prob_price': 474111671, 'views': 92600}, {'id': 549814, 'name': 'Банк 91', 'street': 'Солнечная улица 74', 'city': 'Санкт-Петербург', 'zipcode': 222190, 'floors': 10, 'year': 1766, 'parking': 0, 'prob_price': 103855338, 'views': 73410}, {'id': 805933, 'name': 'Фабрика 34', 'street': 'Морская улица 88', 'city': 'Камбадос', 'zipcode': 401601, 'floors': 9, 'year': 1768, 'parking': 0, 'prob_price': 209829012, 'views': 40960}, {'id': 172959, 'name': 'Ламарий 64', 'street': 'Московская улица 22', 'city': 'Монсон', 'zipcode': 855170, 'floors': 8, 'year': 1769, 'parking': 0, 'prob_price': 356079378, 'views': 31421}, {'id': 845579, 'name': 'Йодль 89', 'street': 'Садовая улица 10', 'city': 'Осера', 'zipcode': 845968, 'floors': 5, 'year': 1773, 'parking': 0, 'prob_price': 861712029, 'views': 43471}, {'id': 849968, 'name': 'Логово 41', 'street': 'Минская улица 40', 'city': 'Осера', 'zipcode': 573342, 'floors': 1, 'year': 1774, 'parking': 1, 'prob_price': 824486436, 'views': 55931}, {'id': 246664, 'name': 'Скворечник 54', 'street': 'Зимняя улица 64', 'city': 'Виго', 'zipcode': 461581, 'floors': 9, 'year': 1778, 'parking': 1, 'prob_price': 396707817, 'views': 71371}]\n"
     ]
    }
   ],
   "source": [
    "first_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(filepath):\n",
    "    try:\n",
    "        df = pd.read_json(filepath,encoding='utf-8')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_sql(df):\n",
    "    try:\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        df.to_sql('task2', conn, if_exists='replace', index=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data):\n",
    "    with open('./Answers/second_task.json', 'w',encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_to_df(filepath):\n",
    "    try:\n",
    "        df = pd.read_pickle(filepath)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query1 = \"\"\"CREATE TABLE IF NOT EXISTS task2_1 (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT UNIQUE NOT NULL,\n",
    "    street TEXT,\n",
    "    city TEXT,\n",
    "    zipcode INTEGER,\n",
    "    floors INTEGER,\n",
    "    year INTEGER,\n",
    "    parking INTEGER,\n",
    "    prob_price REAL,\n",
    "    views INTEGER\n",
    "    );\"\"\"\n",
    "\n",
    "    query2 = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS task2_2 (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    building_name TEXT,\n",
    "    rating REAL,\n",
    "    convenience INTEGER,\n",
    "    security INTEGER,\n",
    "    functionality INTEGER,\n",
    "    comment TEXT,\n",
    "    FOREIGN KEY (building_name) REFERENCES task2_1(name)\n",
    "    );\"\"\"\n",
    "\n",
    "    cursor.execute(query1)\n",
    "    cursor.execute(query2)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(origin_data, description_data):\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute('''\n",
    "            INSERT OR IGNORE INTO task2_1 (id, name, street, city, zipcode, floors, year, parking, prob_price, views) \n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (origin_data['id'], origin_data['name'], origin_data['street'],\n",
    "              origin_data['city'], origin_data['zipcode'], origin_data['floors'],\n",
    "              origin_data['year'], origin_data['parking'], origin_data['prob_price'],\n",
    "              origin_data['views']))\n",
    "\n",
    "        cursor.execute('''\n",
    "            INSERT INTO task2_2 (building_name, rating, convenience, security, functionality, comment) \n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (description_data['name'], description_data['rating'], description_data['convenience'],\n",
    "              description_data['security'], description_data['functionality'], description_data['comment']))\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        conn.rollback()
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_json(json1,json2):\n",
    "    for i,value in enumerate(json1):\n",
    "        origin_data = value\n",
    "        description_data = json2[i]\n",
    "        insert_data(origin_data, description_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query1():\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query1 = '''\n",
    "    SELECT t1.name, t1.city, t1.street, t2.rating, t2.convenience, t2.security, t2.functionality, t2.comment\n",
    "    FROM task2_1 t1\n",
    "    LEFT JOIN task2_2 t2 ON t1.name = t2.building_name\n",
    "    '''\n",
    "    cursor.execute(query1)\n",
    "    results1 = cursor.fetchall()\n",
    "    print(\"Все здания с их описанием\")\n",
    "    for row in results1:\n",
    "        print(row)\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query2():\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query2 = '''\n",
    "    SELECT rating, COUNT(*) as building_count\n",
    "    FROM task2_2\n",
    "    GROUP BY rating\n",
    "    '''\n",
    "    cursor.execute(query2)\n",
    "    results2 = cursor.fetchall()\n",
    "    print(\"Подсчет количество зданий по рейтингу\")\n",
    "    for row in results2:\n",
    "        print(f\"Rating: {row[0]}, Count: {row[1]}\")\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query3():\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    cursor = conn.cursor()\n",
    "    query3 = '''\n",
    "    SELECT t1.name, t1.city, t1.street\n",
    "    FROM task2_1 t1\n",
    "    JOIN task2_2 t2 ON t1.name = t2.building_name\n",
    "    WHERE t2.convenience = ?\n",
    "    '''\n",
    "    cursor.execute(query3, (5,))\n",
    "    results3 = cursor.fetchall()\n",
    "    print(f\"Здания с уровнем {5}\")\n",
    "    for row in results3:\n",
    "        print(row)\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def second_task():\n",
    "    filepath = './55/1-2/subitem.json'\n",
    "    df = json_to_df(filepath)\n",
    "    push_to_sql(df)\n",
    "\n",
    "    create_tables()\n",
    "\n",
    "    origin_json = pickle_to_df('./55/1-2/item.pkl')\n",
    "    description_json = read_json_file(filepath)\n",
    "    insert_json(origin_json,description_json)\n",
    "    print(query1())\n",
    "    print(query2())\n",
    "    print(query3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    second_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath):\n",
    "    df = pd.read_csv(filepath,sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(df,filename):\n",
    "    df.to_json(f'./Answers/{filename}.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file) \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_sql(df,tableName):\n",
    "    try:\n",
    "        conn = sqlite3.connect('database.db')\n",
    "        df.to_sql(tableName, conn, if_exists='replace', index=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_db(db_name):\n",
    "    return sqlite3.connect(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_ten_row(db_name, n, sort_field):\n",
    "    conn = connect_db(db_name)\n",
    "    query = f'''\n",
    "    SELECT * FROM task3\n",
    "    ORDER BY {sort_field}\n",
    "    LIMIT {n}\n",
    "    '''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(db_name, numeric_field):\n",
    "    conn = connect_db(db_name)\n",
    "    query = f'''\n",
    "    SELECT \n",
    "        SUM({numeric_field}) AS total,\n",
    "        MIN({numeric_field}) AS minimum,\n",
    "        MAX({numeric_field}) AS maximum,\n",
    "        AVG({numeric_field}) AS average\n",
    "    FROM task3\n",
    "    '''\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(db_name, categorical_field):\n",
    "    conn = connect_db(db_name)\n",
    "    query = f'''\n",
    "    SELECT {categorical_field}, COUNT(*) AS frequency\n",
    "    FROM task3\n",
    "    GROUP BY {categorical_field}\n",
    "    '''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_rows(db_name, n, predicate, sort_field):\n",
    "    conn = connect_db(db_name)\n",
    "    query = f'''\n",
    "    SELECT * FROM task3\n",
    "    WHERE {predicate}\n",
    "    ORDER BY {sort_field}\n",
    "    LIMIT {n}\n",
    "    '''\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './55/3/_part_1.csv'\n",
    "filepath2 = './55/3/_part_2.json'\n",
    "df1 = read_csv(filepath)\n",
    "df2 = read_json_file(filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([df1,df2],axis=1,keys=['atrtist','song'])\n",
    "result_df.columns = ['_'.join(col).strip() for col in result_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_to_sql(result_df,'task3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        total  minimum  maximum     average\n",
      "0  135424.075   60.019   205.57  120.270049\n"
     ]
    }
   ],
   "source": [
    "def third_task():\n",
    "    db_name = 'database.db' \n",
    "    \n",
    "    df = first_ten_row(db_name, 10, 'atrtist_duration_ms')\n",
    "    save_json(df,'task3_1')\n",
    "\n",
    "    stats = statistics(db_name, 'atrtist_tempo')\n",
    "    print(stats)\n",
    "\n",
    "    df = frequency_df = frequency(db_name, 'atrtist_genre')\n",
    "    save_json(df,'task3_2')\n",
    "\n",
    "    df = filtered_rows(db_name, 15, \"atrtist_energy > 0.5\", 'atrtist_energy')\n",
    "    save_json(df,'task3_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    third_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS products (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT NOT NULL UNIQUE,\n",
    "        price REAL NOT NULL CHECK(price >= 0),\n",
    "        quantity INTEGER NOT NULL CHECK(quantity >= 0),\n",
    "        category TEXT,\n",
    "        fromCity TEXT,\n",
    "        isAvailable BOOLEAN,\n",
    "        views INTEGER,\n",
    "        update_counter INTEGER DEFAULT 0\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_products_from_json(db_name, json_file):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        products = json.load(f)\n",
    "    \n",
    "    for product in products:\n",
    "        cursor.execute('''\n",
    "        INSERT INTO products (name, price, quantity, category, fromCity, isAvailable, views)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ON CONFLICT(name) DO UPDATE SET\n",
    "            price = excluded.price,\n",
    "            quantity = excluded.quantity,\n",
    "            category = excluded.category,\n",
    "            fromCity = excluded.fromCity,\n",
    "            isAvailable = excluded.isAvailable,\n",
    "            views = excluded.views,\n",
    "            update_counter = update_counter + 1\n",
    "        ''', (product['name'], product['price'], product['quantity'], product.get('category'), \n",
    "              product['fromCity'], product['isAvailable'], product['views']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_commands_from_csv(db_name, csv_file):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    df = pd.read_csv(csv_file, sep=';')\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        name = row['name']\n",
    "        method = row['method']\n",
    "        param = row['param']\n",
    "        \n",
    "        if method == 'available':\n",
    "            cursor.execute('''\n",
    "            UPDATE products\n",
    "            SET isAvailable = ?, update_counter = update_counter + 1\n",
    "            WHERE name = ?\n",
    "            ''', (param == 'True', name))\n",
    "        \n",
    "        elif method == 'remove':\n",
    "            cursor.execute('DELETE FROM products WHERE name = ?', (name,))\n",
    "        \n",
    "        elif method == 'quantity_add':\n",
    "            cursor.execute('''\n",
    "            UPDATE products\n",
    "            SET quantity = quantity + ?, update_counter = update_counter + 1\n",
    "            WHERE name = ?\n",
    "            ''', (int(param), name))\n",
    "        \n",
    "        elif method == 'price_abs':\n",
    "            cursor.execute('''\n",
    "            UPDATE products\n",
    "            SET price = ?, update_counter = update_counter + 1\n",
    "            WHERE name = ? AND ? >= 0\n",
    "            ''', (float(param), name, float(param)))\n",
    "        \n",
    "        elif method == 'price_percent':\n",
    "            cursor.execute('''\n",
    "            UPDATE products\n",
    "            SET price = price * (1 + ?), update_counter = update_counter + 1\n",
    "            WHERE name = ?\n",
    "            ''', (float(param), name))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_updated_products(db_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    SELECT name, update_counter\n",
    "    FROM products\n",
    "    ORDER BY update_counter DESC\n",
    "    LIMIT 10\n",
    "    ''')\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_prices(db_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    SELECT AVG(price), MIN(price), MAX(price)\n",
    "    FROM products\n",
    "    WHERE isAvailable = 1\n",
    "    ''')\n",
    "    \n",
    "    results = cursor.fetchone()\n",
    "    conn.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ 10 товаров\n",
      "('Epson Expression Home XP', 55)\n",
      "('luxurious plum', 43)\n",
      "('gorgeous windows', 43)\n",
      "('elegant baseboard', 35)\n",
      "('magnificent blueberry', 35)\n",
      "('glamorous face wash', 35)\n",
      "('magnificent baseboard', 31)\n",
      "('attractive screws', 31)\n",
      "('marvelous roofing', 31)\n",
      "('exquisite drywall', 31)\n",
      "\n",
      "\n",
      "Среднее, Максимальное, минимальное: (629.4814901272728, 0.0, 12608.0)\n"
     ]
    }
   ],
   "source": [
    "def fourth_task():\n",
    "    create_database('database.db')\n",
    "    load_products_from_json('database.db', './55/4/_product_data.json')\n",
    "    process_commands_from_csv('database.db', './55/4/_update_data.csv')\n",
    "\n",
    "    top_updated = display_top_updated_products('database.db')\n",
    "    print('Топ 10 товаров')\n",
    "    for product in top_updated:\n",
    "        print(product)\n",
    "    print('\\n')\n",
    "    price_analysis = analyze_prices('database.db')\n",
    "    print(\"Среднее, Максимальное, минимальное:\", price_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    fourth_task()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
